{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e85f0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MediaPipe version: 0.10.9\n",
      "Detected 1 RealSense device(s).\n",
      "Error starting RealSense camera: MFCreateDeviceSource(_device_attrs, &_source) returned: HResult 0x800701b1: \"A device which does not exist was specified.\". Ensure the camera is connected via USB 3.0 and no other apps are using it.\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import open3d as o3d\n",
    "\n",
    "class RealSenseFaceScanner:\n",
    "    def __init__(self):\n",
    "        # Initialize MediaPipe Face Mesh with refined landmarks for iris detection\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.mp_drawing_styles = mp.solutions.drawing_styles\n",
    "        self.FACEMESH_TESSELATION = mp.solutions.face_mesh.FACEMESH_TESSELATION  # Added for connections\n",
    "\n",
    "        # Initialize RealSense pipeline and configuration\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.depth, 848, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)\n",
    "\n",
    "        # Alignment object to align depth to color\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # Post-processing filters\n",
    "        # Decimation filter (optional, commented out for now as it's low priority)\n",
    "        # self.decimation = rs.decimation_filter()\n",
    "        # self.decimation.set_option(rs.option.filter_magnitude, 2)\n",
    "\n",
    "        # Spatial filter for edge-preserving smoothing\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.spatial.set_option(rs.option.filter_magnitude, 5)\n",
    "        self.spatial.set_option(rs.option.filter_smooth_alpha, 0.5)\n",
    "        self.spatial.set_option(rs.option.filter_smooth_delta, 20)\n",
    "        self.spatial.set_option(rs.option.holes_fill, 2)  # Small hole filling\n",
    "\n",
    "        # Temporal filter for reducing temporal noise\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.temporal.set_option(rs.option.filter_smooth_alpha, 0.4)\n",
    "        self.temporal.set_option(rs.option.filter_smooth_delta, 20)\n",
    "        self.temporal.set_option(rs.option.holes_fill, 3)  # Persistence for temporal\n",
    "\n",
    "        # Hole filling filter (critical for handling occlusions like hair/glasses)\n",
    "        self.hole_filling = rs.hole_filling_filter(2)  # 2: nearest neighbor filling\n",
    "\n",
    "        # Key landmarks for measurements (MediaPipe indices)\n",
    "        self.key_landmarks = {\n",
    "            1: 'nose_tip',      # Nose tip for distance to camera\n",
    "            10: 'forehead',     # Forehead for face height\n",
    "            152: 'chin',        # Chin for face height\n",
    "            129: 'left_nose_wing',  # Left nose wing for nose width\n",
    "            358: 'right_nose_wing', # Right nose wing for nose width\n",
    "            468: 'right_iris',  # Right iris center (note: MediaPipe labels right as 468, left as 473)\n",
    "            473: 'left_iris',   # Left iris center\n",
    "            33: 'left_eye_corner',  # Left eye outer corner (fallback for IPD)\n",
    "            263: 'right_eye_corner' # Right eye outer corner (fallback for IPD)\n",
    "        }\n",
    "\n",
    "        # [BỔSUNG] Biến lưu tọa độ khi người dùng click chuột\n",
    "        self.clicked_point = None\n",
    "\n",
    "    # [BỔSUNG] Hàm callback để bắt sự kiện chuột từ OpenCV\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\"\n",
    "        Mouse event callback: Captures left mouse clicks and stores pixel coordinates\n",
    "        for interactive depth measurement.\n",
    "        :param event: Event type (LBUTTONDOWN, etc.)\n",
    "        :param x, y: Pixel coordinates of mouse click\n",
    "        \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:  # Khi nhấn chuột trái\n",
    "            self.clicked_point = (x, y)     # Lưu tọa độ (u, v) lại\n",
    "            print(f\"[Mouse Event] Clicked at pixel: ({x}, {y})\")\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, height, width, window_size=3):\n",
    "        \"\"\"\n",
    "        Get the average depth in a small window around (x, y) to handle invalid (0) depths.\n",
    "        This helps with noisy or missing depth values, e.g., on hair or reflective surfaces.\n",
    "        :param depth_frame: Aligned depth frame\n",
    "        :param x, y: Pixel coordinates\n",
    "        :param height, width: Frame dimensions\n",
    "        :param window_size: Size of the square window (odd number)\n",
    "        :return: Average depth (meters) or 0 if no valid depths found\n",
    "        \"\"\"\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < width and 0 <= ny < height:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0:\n",
    "                        depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def show_voxel_grid(self, depth_frame):\n",
    "        \"\"\"\n",
    "        Generate and display a downsampled voxel grid from the depth frame's point cloud.\n",
    "        Includes white point coloring, coordinate axes for orientation, and proper flip\n",
    "        to handle RealSense vs Open3D coordinate system differences.\n",
    "        :param depth_frame: Processed depth frame\n",
    "        \"\"\"\n",
    "        print(\"[Snapshot] Processing 3D data...\")\n",
    "        \n",
    "        # 1. Create Point Cloud from RealSense\n",
    "        pc = rs.pointcloud()\n",
    "        points = pc.calculate(depth_frame)\n",
    "        \n",
    "        # 2. Extract vertices\n",
    "        vertices = np.asanyarray(points.get_vertices()).view(np.float32).reshape(-1, 3)\n",
    "        \n",
    "        # Check if point cloud has data\n",
    "        if len(vertices) == 0:\n",
    "            print(\"[Warning] Point cloud is empty! (Check depth camera)\")\n",
    "            return\n",
    "\n",
    "        print(f\"[Snapshot] Raw points: {len(vertices)}\")\n",
    "\n",
    "        # 3. Create Open3D Point Cloud\n",
    "        pcd = o3d.geometry.PointCloud()\n",
    "        pcd.points = o3d.utility.Vector3dVector(vertices)\n",
    "        \n",
    "        # --- CRITICAL FIX: Color points & flip coordinates ---\n",
    "        \n",
    "        # a. Paint all points WHITE to stand out on black background\n",
    "        pcd.paint_uniform_color([1, 1, 1]) \n",
    "        \n",
    "        # b. Downsample with smaller voxel size for better detail\n",
    "        pcd_down = pcd.voxel_down_sample(voxel_size=0.03)  # 0.03m for finer grid\n",
    "        print(f\"[Snapshot] Voxel points: {len(pcd_down.points)}\")\n",
    "\n",
    "        # c. Create coordinate frame (X=Red, Y=Green, Z=Blue) for orientation reference\n",
    "        # Size is 0.5 meters\n",
    "        mesh_frame = o3d.geometry.TriangleMesh.create_coordinate_frame(size=0.5, origin=[0, 0, 0])\n",
    "\n",
    "        # d. Flip point cloud (RealSense and Open3D have opposite Y and Z axes)\n",
    "        # Flip Y and Z so the face appears upright instead of upside-down\n",
    "        pcd_down.transform([[1, 0, 0, 0], [0, -1, 0, 0], [0, 0, -1, 0], [0, 0, 0, 1]])\n",
    "\n",
    "        # 4. Display\n",
    "        print(\"[Snapshot] Opening 3D Viewer... (Close window to continue)\")\n",
    "        o3d.visualization.draw_geometries([pcd_down, mesh_frame], \n",
    "                                          window_name=\"3D Voxel Grid Snapshot\",\n",
    "                                          width=800, height=600)\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            print(\"MediaPipe version:\", mp.__version__)  # Debug version\n",
    "\n",
    "            # Debugging: Check devices and USB type\n",
    "            ctx = rs.context()\n",
    "            devices = ctx.query_devices()\n",
    "            if len(devices) == 0:\n",
    "                raise RuntimeError(\"No RealSense devices detected. Check connection.\")\n",
    "            print(f\"Detected {len(devices)} RealSense device(s).\")\n",
    "            dev = devices[0]\n",
    "            usb_type = dev.get_info(rs.camera_info.usb_type_descriptor)\n",
    "            print(f\"Device: {dev.get_info(rs.camera_info.name)}, USB Type: {usb_type}\")\n",
    "            \n",
    "            # Debugging: List supported stream profiles\n",
    "            print(\"Supported stream profiles:\")\n",
    "            for sensor in dev.query_sensors():\n",
    "                print(f\"Sensor: {sensor.get_info(rs.camera_info.name)}\")\n",
    "                for profile in sensor.get_stream_profiles():\n",
    "                    if profile.stream_type() == rs.stream.depth or profile.stream_type() == rs.stream.color:\n",
    "                        print(profile)\n",
    "\n",
    "            # Try starting with primary config\n",
    "            try:\n",
    "                self.pipeline.start(self.config)\n",
    "                pipeline_started = True\n",
    "                print(\"RealSense camera started successfully with primary config.\")\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Primary config failed: {e}. Falling back to lower resolution.\")\n",
    "                # Fallback config (safer for USB2/compatibility)\n",
    "                fallback_config = rs.config()\n",
    "                fallback_config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "                fallback_config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "                self.pipeline.start(fallback_config)\n",
    "                pipeline_started = True\n",
    "                print(\"Started with fallback config (640x480).\")\n",
    "\n",
    "            # [BỔSUNG] Đăng ký cửa sổ & chuột (Trước vòng lặp while True)\n",
    "            window_name = '3D Facial Analysis & Interactive Measure'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            while True:\n",
    "                # Wait for frames and align depth to color\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "\n",
    "                # Apply post-processing filters in order\n",
    "                # depth_frame = self.decimation.process(depth_frame)  # Optional\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame)\n",
    "                \n",
    "                # CRITICAL FIX: Cast back to depth_frame to get .get_distance() method\n",
    "                depth_frame = depth_frame.as_depth_frame()\n",
    "\n",
    "                # Get image data as NumPy arrays\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                print(\"Color frame shape:\", color_image.shape)  # Debug\n",
    "                depth_image = np.asanyarray(depth_frame.get_data())  # For reference if needed\n",
    "\n",
    "                # Convert to RGB for MediaPipe processing\n",
    "                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "                results = self.mp_face_mesh.process(rgb_image)\n",
    "                if results.multi_face_landmarks:\n",
    "                    print(\"Face detected!\")  # Debug\n",
    "                else:\n",
    "                    print(\"No face detected.\")  # Debug\n",
    "\n",
    "                # Get frame dimensions\n",
    "                height, width = color_image.shape[:2]\n",
    "\n",
    "                # Draw face mesh and compute 3D points if face detected\n",
    "                if results.multi_face_landmarks:\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "                        # Vẽ lưới mặt với màu xanh lá đơn giản, không dùng style mặc định gây lỗi\n",
    "                        self.mp_drawing.draw_landmarks(\n",
    "                            image=color_image,\n",
    "                            landmark_list=face_landmarks,\n",
    "                            connections=self.FACEMESH_TESSELATION,\n",
    "                            landmark_drawing_spec=None,  # Không vẽ chấm tròn\n",
    "                            connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1, circle_radius=1)\n",
    "                        )\n",
    "\n",
    "                        # Get color intrinsics for deprojection\n",
    "                        color_intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "\n",
    "                        # Compute 3D points for key landmarks\n",
    "                        points_3d = {}\n",
    "                        for idx, name in self.key_landmarks.items():\n",
    "                            lm = face_landmarks.landmark[idx]\n",
    "                            u = int(lm.x * width)\n",
    "                            v = int(lm.y * height)\n",
    "                            # Get average depth in a small window to handle invalid values\n",
    "                            depth = self.get_average_depth(depth_frame, u, v, height, width)\n",
    "                            if depth > 0:\n",
    "                                # Deproject pixel to 3D point\n",
    "                                # Math: The deprojection transforms 2D pixel (u, v) with depth d to 3D (X, Y, Z) in meters\n",
    "                                # using camera intrinsics (fx, fy, ppx, ppy): X = (u - ppx) * d / fx, Y = (v - ppy) * d / fy, Z = d\n",
    "                                point_3d = rs.rs2_deproject_pixel_to_point(color_intrinsics, [u, v], depth)\n",
    "                                points_3d[name] = np.array(point_3d)\n",
    "\n",
    "                        # Calculate and display biometric measurements\n",
    "                        text_pos = 30\n",
    "                        if 'nose_tip' in points_3d:\n",
    "                            # Distance to camera: Euclidean norm from (0,0,0) to nose tip\n",
    "                            # Math: dist = sqrt(X^2 + Y^2 + Z^2)\n",
    "                            dist_cam = np.linalg.norm(points_3d['nose_tip'])\n",
    "                            color = (0, 255, 0) if dist_cam >= 0.4 else (0, 0, 255)\n",
    "                            cv2.putText(color_image, f\"Distance to Camera: {dist_cam:.2f} m\", (10, text_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "                            text_pos += 30\n",
    "\n",
    "                        if 'left_iris' in points_3d and 'right_iris' in points_3d:\n",
    "                            # IPD: Euclidean distance between iris centers\n",
    "                            # Math: dist = sqrt( (X2 - X1)^2 + (Y2 - Y1)^2 + (Z2 - Z1)^2 )\n",
    "                            ipd = np.linalg.norm(points_3d['left_iris'] - points_3d['right_iris'])\n",
    "                            cv2.putText(color_image, f\"IPD: {ipd:.2f} m\", (10, text_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                            text_pos += 30\n",
    "                        elif 'left_eye_corner' in points_3d and 'right_eye_corner' in points_3d:\n",
    "                            # Fallback to eye corners if iris not available\n",
    "                            ipd = np.linalg.norm(points_3d['left_eye_corner'] - points_3d['right_eye_corner'])\n",
    "                            cv2.putText(color_image, f\"IPD (fallback): {ipd:.2f} m\", (10, text_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                            text_pos += 30\n",
    "\n",
    "                        if 'forehead' in points_3d and 'chin' in points_3d:\n",
    "                            face_height = np.linalg.norm(points_3d['forehead'] - points_3d['chin'])\n",
    "                            cv2.putText(color_image, f\"Face Height: {face_height:.2f} m\", (10, text_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                            text_pos += 30\n",
    "\n",
    "                        if 'left_nose_wing' in points_3d and 'right_nose_wing' in points_3d:\n",
    "                            nose_width = np.linalg.norm(points_3d['left_nose_wing'] - points_3d['right_nose_wing'])\n",
    "                            cv2.putText(color_image, f\"Nose Width: {nose_width:.2f} m\", (10, text_pos), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "                            text_pos += 30\n",
    "\n",
    "                # [BỔSUNG] Logic hiển thị điểm click chuột\n",
    "                if self.clicked_point:\n",
    "                    cx, cy = self.clicked_point\n",
    "                    \n",
    "                    # 1. Lấy độ sâu tại điểm click (Dùng hàm get_average_depth có sẵn)\n",
    "                    dist_click = self.get_average_depth(depth_frame, cx, cy, height, width)\n",
    "                    \n",
    "                    # 2. Vẽ dấu cộng màu đỏ để đánh dấu\n",
    "                    cv2.drawMarker(color_image, (cx, cy), (0, 0, 255), cv2.MARKER_CROSS, 20, 2)\n",
    "                    \n",
    "                    # 3. Hiển thị text khoảng cách\n",
    "                    if dist_click > 0:\n",
    "                        text = f\"Clicked Depth: {dist_click:.3f} m\"\n",
    "                        # Vẽ nền đen nhỏ cho chữ dễ đọc\n",
    "                        cv2.rectangle(color_image, (cx + 10, cy - 25), (cx + 250, cy + 5), (0, 0, 0), -1)\n",
    "                        cv2.putText(color_image, text, (cx + 10, cy - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
    "                        print(f\"[Measurement] Clicked depth at ({cx}, {cy}): {dist_click:.3f} m\")\n",
    "\n",
    "                # Display the image (AFTER all drawing operations)\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                # Handle key presses\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    # Snapshot and show voxel grid on 's' press\n",
    "                    self.show_voxel_grid(depth_frame)\n",
    "                elif key == ord('c'):\n",
    "                    # Clear clicked point on 'c' press\n",
    "                    self.clicked_point = None\n",
    "                    print(\"[Control] Clicked point cleared\")\n",
    "\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Error starting RealSense camera: {e}. Ensure the camera is connected via USB 3.0 and no other apps are using it.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "        finally:\n",
    "            # Cleanup - only stop if pipeline was started\n",
    "            if pipeline_started:\n",
    "                self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "# Usage: Instantiate and run the scanner\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = RealSenseFaceScanner()\n",
    "    scanner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949c7854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "* HƯỚNG DẪN: Ngồi cách camera 0.5m. Nhấn S để lưu Mesh CÓ MÀU DA THẬT.\n",
      "\n",
      "\n",
      "==================================================\n",
      "[3D SNAPSHOT] ĐANG TẠO MÔ HÌNH 3D CÓ MÀU SẮC...\n",
      "[Xử lý] Đang dọn sạch các vệt nhiễu dọc...\n",
      "[Mesh] Đang tính toán bề mặt Mesh...\n",
      "[THÀNH CÔNG] Đã lưu mô hình CÓ MÀU tại: d:\\FaceGrid3D\\face_3d_colored_clean.ply\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "class RealSenseFaceScanner:\n",
    "    def __init__(self):\n",
    "        # 1. Khởi tạo MediaPipe Face Mesh\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.FACEMESH_TESSELATION = mp.solutions.face_mesh.FACEMESH_TESSELATION\n",
    "\n",
    "        # 2. Khởi tạo RealSense\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        # Sử dụng cấu hình ổn định nhất cho D455\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # 3. Các bộ lọc xử lý nhiễu\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.hole_filling = rs.hole_filling_filter(2) \n",
    "\n",
    "        self.clicked_point = None\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.clicked_point = (x, y)\n",
    "            print(f\"[Sự kiện chuột] Tọa độ: ({x}, {y})\")\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, height, width, window_size=5):\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < width and 0 <= ny < height:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0: depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def show_3d_snapshot(self, depth_frame, color_frame):\n",
    "        \"\"\" \n",
    "        PHIÊN BẢN CÓ MÀU THẬT - LỌC NHIỄU TUYỆT ĐỐI:\n",
    "        - Sử dụng Color Mapping để đắp màu thực tế lên mặt.\n",
    "        - Lọc Statistical Outlier để xóa vệt dọc.\n",
    "        - Tạo Mesh có màu sắc để Meshmixer không báo lỗi.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"[3D SNAPSHOT] ĐANG TẠO MÔ HÌNH 3D CÓ MÀU SẮC...\")\n",
    "            \n",
    "            # 1. Lấy dữ liệu màu thực tế\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            # Chuẩn hóa màu sang RGB dải [0, 1] cho Open3D\n",
    "            color_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            # 2. Tạo Point Cloud và ánh xạ vân bề mặt\n",
    "            pc = rs.pointcloud()\n",
    "            pc.map_to(color_frame)\n",
    "            points = pc.calculate(depth_frame)\n",
    "            v = points.get_vertices()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(-1, 3)\n",
    "            \n",
    "            # 3. Lọc vùng mặt (Crop) - Giới hạn 0.2m đến 0.8m để tránh nhiễu xa\n",
    "            valid_mask = (verts[:, 2] > 0.1) & (verts[:, 2] < 1.0) & np.all(np.isfinite(verts), axis=1)\n",
    "            if np.sum(valid_mask) < 2000:\n",
    "                print(\"[LỖI] Không đủ dữ liệu mặt. Hãy ngồi gần camera hơn!\")\n",
    "                return\n",
    "\n",
    "            valid_verts = verts[valid_mask]\n",
    "            # Lấy màu tương ứng cho từng điểm\n",
    "            valid_colors = color_rgb.reshape(-1, 3)[valid_mask]\n",
    "\n",
    "            # 4. Tạo PointCloud và xóa vệt nhiễu (Statistical Outlier Removal)\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(valid_verts)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(valid_colors)\n",
    "\n",
    "            print(\"[Xử lý] Đang dọn sạch các vệt nhiễu dọc...\")\n",
    "            cl, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=1.0)\n",
    "            pcd = pcd.select_by_index(ind)\n",
    "\n",
    "            # 5. TẠO BỀ MẶT MESH CÓ MÀU\n",
    "            print(\"[Mesh] Đang tính toán bề mặt Mesh...\")\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.03, max_nn=30))\n",
    "            pcd.orient_normals_towards_camera_location(camera_location=[0, 0, 0])\n",
    "            \n",
    "            # Sử dụng Ball Pivoting để tạo lưới tam giác\n",
    "            distances = pcd.compute_nearest_neighbor_distance()\n",
    "            avg_dist = np.mean(distances)\n",
    "            radius = 2 * avg_dist\n",
    "            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "                pcd, o3d.utility.DoubleVector([radius, radius * 2])\n",
    "            )\n",
    "\n",
    "            # QUAN TRỌNG: Gán màu cho các đỉnh của Mesh\n",
    "            mesh.vertex_colors = pcd.colors\n",
    "\n",
    "            # 6. Lưu file PLY định dạng ASCII chuẩn (Có màu, có mặt)\n",
    "            filename = \"face_3d_colored_clean.ply\"\n",
    "            o3d.io.write_triangle_mesh(filename, mesh, write_ascii=True)\n",
    "            \n",
    "            full_path = os.path.abspath(filename)\n",
    "            print(f\"[THÀNH CÔNG] Đã lưu mô hình CÓ MÀU tại: {full_path}\")\n",
    "            \n",
    "            # Tự động mở file bằng Windows 3D Viewer\n",
    "            os.startfile(full_path)\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LỖI] Quá trình thất bại: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "            pipeline_started = True\n",
    "            \n",
    "            # Tối ưu chế độ quét High Density\n",
    "            device = profile.get_device()\n",
    "            depth_sensor = device.query_sensors()[0]\n",
    "            if depth_sensor.supports(rs.option.visual_preset):\n",
    "                depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "\n",
    "            window_name = 'SCANNER 3D - NHAN S DE CHUP MAT CO MAU'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            print(\"\\n* HƯỚNG DẪN: Ngồi cách camera 0.5m. Nhấn S để lưu Mesh CÓ MÀU DA THẬT.\\n\")\n",
    "\n",
    "            while True:\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "                if not depth_frame or not color_frame: continue\n",
    "\n",
    "                # Bộ lọc làm mịn\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame).as_depth_frame()\n",
    "\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                h, w = color_image.shape[:2]\n",
    "                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "                results = self.mp_face_mesh.process(rgb_image)\n",
    "\n",
    "                # Hiển thị khoảng cách hỗ trợ căn chỉnh\n",
    "                dist_center = self.get_average_depth(depth_frame, w//2, h//2, h, w)\n",
    "                color_dist = (0, 255, 0) if 0.4 <= dist_center <= 0.6 else (0, 0, 255)\n",
    "                cv2.putText(color_image, f\"Distance: {dist_center:.2f}m\", (10, 30), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, color_dist, 2)\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    for face_landmarks in results.multi_face_landmarks:\n",
    "                        self.mp_drawing.draw_landmarks(\n",
    "                            image=color_image, landmark_list=face_landmarks,\n",
    "                            connections=self.FACEMESH_TESSELATION,\n",
    "                            connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                        )\n",
    "\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'): break\n",
    "                elif key == ord('s'):\n",
    "                    self.show_3d_snapshot(depth_frame, color_frame)\n",
    "                elif key == ord('c'):\n",
    "                    self.clicked_point = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "        finally:\n",
    "            if pipeline_started: self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = RealSenseFaceScanner()\n",
    "    scanner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a40d5111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> HƯỚNG DẪN: Đảm bảo Distance hiển thị màu Xanh. Nhấn 'S' để chụp Mesh chuẩn MeshLab.\n",
      "[Mouse Event] Tọa độ chọn: (222, 130)\n",
      "[Mouse Event] Tọa độ chọn: (233, 130)\n",
      "[Mouse Event] Tọa độ chọn: (258, 130)\n",
      "[Mouse Event] Tọa độ chọn: (295, 160)\n",
      "[Mouse Event] Tọa độ chọn: (361, 201)\n",
      "[Mouse Event] Tọa độ chọn: (393, 230)\n",
      "[Mouse Event] Tọa độ chọn: (280, 235)\n",
      "[Mouse Event] Tọa độ chọn: (124, 202)\n",
      "[Mouse Event] Tọa độ chọn: (242, 186)\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "class RealSenseFaceScanner:\n",
    "    def __init__(self):\n",
    "        # 1. Khởi tạo MediaPipe Face Mesh (Refine landmarks để lấy vùng mắt/môi chuẩn)\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.6\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.FACEMESH_TESSELATION = mp.solutions.face_mesh.FACEMESH_TESSELATION\n",
    "\n",
    "        # 2. Khởi tạo RealSense D455\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        # D455 chạy ổn định nhất ở 640x480 để giảm nhiễu mép\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # 3. Các bộ lọc xử lý nhiễu\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.hole_filling = rs.hole_filling_filter(2) \n",
    "\n",
    "        # Các landmark quan trọng để đo đạc sinh trắc học\n",
    "        self.key_landmarks = {\n",
    "            1: 'nose_tip',\n",
    "            10: 'forehead',\n",
    "            152: 'chin',\n",
    "            129: 'left_nose_wing',\n",
    "            358: 'right_nose_wing',\n",
    "            468: 'right_iris',\n",
    "            473: 'left_iris'\n",
    "        }\n",
    "\n",
    "        self.clicked_point = None\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\" Xử lý sự kiện click chuột để lấy tọa độ pixel \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.clicked_point = (x, y)\n",
    "            print(f\"[Mouse Event] Tọa độ chọn: ({x}, {y})\")\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, h, w, window_size=5):\n",
    "        \"\"\" Tính độ sâu trung bình trong vùng nhỏ \"\"\"\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < w and 0 <= ny < h:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0: depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def show_3d_snapshot(self, depth_frame, color_frame, face_landmarks):\n",
    "        \"\"\" \n",
    "        PHIÊN BẢN TỐI ƯU CHO MESHLAB:\n",
    "        - Sử dụng mặt nạ MediaPipe để lọc nhiễu 100%.\n",
    "        - Căn giữa dữ liệu (Normalization) để MeshLab không bị tối thui.\n",
    "        - Tính toán lại pháp tuyến và gán màu sắc chuẩn xác cho Mesh.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"[3D SNAPSHOT] ĐANG TẠO MESH CHUẨN MESHLAB...\")\n",
    "            \n",
    "            # 1. Chuẩn bị dữ liệu ảnh\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            h, w = color_image.shape[:2]\n",
    "            color_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            # 2. TẠO MẶT NẠ (MASK) TỪ LANDMARKS ĐỂ LỌC VÙNG MẶT\n",
    "            face_oval_indices = [\n",
    "                10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, \n",
    "                397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, \n",
    "                172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109\n",
    "            ]\n",
    "            points = []\n",
    "            for idx in face_oval_indices:\n",
    "                lm = face_landmarks.landmark[idx]\n",
    "                points.append([int(lm.x * w), int(lm.y * h)])\n",
    "            \n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [np.array(points)], 255)\n",
    "\n",
    "            # 3. Tính toán mây điểm (Point Cloud)\n",
    "            pc = rs.pointcloud()\n",
    "            pc.map_to(color_frame)\n",
    "            points_3d_all = pc.calculate(depth_frame)\n",
    "            v = points_3d_all.get_vertices()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(h, w, 3)\n",
    "            \n",
    "            # 4. TRÍCH XUẤT ĐIỂM DỰA TRÊN MẶT NẠ\n",
    "            valid_indices = np.where((mask > 0) & (verts[:, :, 2] > 0.1) & (verts[:, :, 2] < 1.0))\n",
    "            final_verts = verts[valid_indices]\n",
    "            final_colors = color_rgb[valid_indices]\n",
    "\n",
    "            if len(final_verts) < 2000:\n",
    "                print(\"[LỖI] Không đủ dữ liệu mặt. Hãy ngồi gần camera hơn!\")\n",
    "                return\n",
    "\n",
    "            # 5. Tạo Point Cloud và Xử lý Hệ tọa độ\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(final_verts)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(final_colors)\n",
    "\n",
    "            # Lọc nhiễu thống kê\n",
    "            pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=1.5)\n",
    "\n",
    "            # CĂN GIỮA DỮ LIỆU (Normalization): Giúp MeshLab tìm thấy vật thể ngay tại gốc tọa độ\n",
    "            pcd.translate(-pcd.get_center())\n",
    "\n",
    "            # XOAY HƯỚNG (Fix Flip): Xoay 180 độ quanh trục X để mặt đứng thẳng\n",
    "            R = pcd.get_rotation_matrix_from_axis_angle([np.pi, 0, 0])\n",
    "            pcd.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "            # ƯỚC TÍNH PHÁP TUYẾN\n",
    "            print(\"[Xử lý] Đang tính toán pháp tuyến bề mặt...\")\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.03, max_nn=30))\n",
    "            # Hướng pháp tuyến về phía camera (bây giờ camera ảo coi như ở phía trước trục Z)\n",
    "            pcd.orient_normals_towards_camera_location(camera_location=[0, 0, 10])\n",
    "\n",
    "            # 6. DỰNG HÌNH BỀ MẶT (Triangle Mesh)\n",
    "            print(\"[Mesh] Đang dựng lưới bề mặt (Ball Pivoting)...\")\n",
    "            distances = pcd.compute_nearest_neighbor_distance()\n",
    "            avg_dist = np.mean(distances)\n",
    "            radius = 2 * avg_dist\n",
    "            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "                pcd, o3d.utility.DoubleVector([radius, radius * 2])\n",
    "            )\n",
    "\n",
    "            # GÁN MÀU SẮC CHO MESH: Đảm bảo MeshLab hiển thị màu da thật\n",
    "            mesh.vertex_colors = pcd.colors\n",
    "\n",
    "            # 7. LƯU FILE CHUẨN\n",
    "            filename = \"face_mesh_meshlab_ready.ply\"\n",
    "            o3d.io.write_triangle_mesh(filename, mesh)\n",
    "            \n",
    "            full_path = os.path.abspath(filename)\n",
    "            print(f\"[THÀNH CÔNG] File 3D chuẩn đã sẵn sàng: {full_path}\")\n",
    "            \n",
    "            # Tự động mở file\n",
    "            os.startfile(full_path)\n",
    "            print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LỖI] {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "            pipeline_started = True\n",
    "            \n",
    "            # Tối ưu chế độ quét High Density cho Face Scanning\n",
    "            device = profile.get_device()\n",
    "            depth_sensor = device.query_sensors()[0]\n",
    "            if depth_sensor.supports(rs.option.visual_preset):\n",
    "                depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "\n",
    "            window_name = 'DESLAB 3D SCANNER - PRO EDITION'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            current_landmarks = None\n",
    "\n",
    "            print(\"\\n>>> HƯỚNG DẪN: Đảm bảo Distance hiển thị màu Xanh. Nhấn 'S' để chụp Mesh chuẩn MeshLab.\")\n",
    "\n",
    "            while True:\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "                if not depth_frame or not color_frame: continue\n",
    "\n",
    "                # Áp dụng bộ lọc Depth\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame).as_depth_frame()\n",
    "\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                h, w = color_image.shape[:2]\n",
    "                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "                results = self.mp_face_mesh.process(rgb_image)\n",
    "\n",
    "                # Hiển thị thước đo khoảng cách\n",
    "                d_center = self.get_average_depth(depth_frame, w//2, h//2, h, w)\n",
    "                color_status = (0, 255, 0) if 0.45 <= d_center <= 0.6 else (0, 0, 255)\n",
    "                cv2.putText(color_image, f\"Distance: {d_center:.2f}m\", (10, 40), 0, 0.7, color_status, 2)\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    current_landmarks = results.multi_face_landmarks[0]\n",
    "                    # Vẽ lưới Face Mesh để người dùng căn chỉnh\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        image=color_image, landmark_list=current_landmarks,\n",
    "                        connections=self.FACEMESH_TESSELATION,\n",
    "                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                    )\n",
    "\n",
    "                    # Tính toán đo đạc IPD (mm) và Chiều cao mặt (cm) thời gian thực\n",
    "                    color_intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "                    points_3d = {}\n",
    "                    for idx, name in self.key_landmarks.items():\n",
    "                        lm = current_landmarks.landmark[idx]\n",
    "                        u, v = int(lm.x * w), int(lm.y * h)\n",
    "                        depth = self.get_average_depth(depth_frame, u, v, h, w)\n",
    "                        if depth > 0:\n",
    "                            pt = rs.rs2_deproject_pixel_to_point(color_intrinsics, [u, v], depth)\n",
    "                            points_3d[name] = np.array(pt)\n",
    "\n",
    "                    y_off = 70\n",
    "                    if 'left_iris' in points_3d and 'right_iris' in points_3d:\n",
    "                        ipd = np.linalg.norm(points_3d['left_iris'] - points_3d['right_iris']) * 1000\n",
    "                        cv2.putText(color_image, f\"IPD: {ipd:.1f} mm\", (10, y_off), 0, 0.6, (255, 255, 0), 2)\n",
    "                        y_off += 25\n",
    "                    \n",
    "                    if 'forehead' in points_3d and 'chin' in points_3d:\n",
    "                        f_h = np.linalg.norm(points_3d['forehead'] - points_3d['chin']) * 100\n",
    "                        cv2.putText(color_image, f\"Face Height: {f_h:.1f} cm\", (10, y_off), 0, 0.6, (255, 255, 0), 2)\n",
    "\n",
    "                # Hiển thị điểm click chuột\n",
    "                if self.clicked_point:\n",
    "                    cx, cy = self.clicked_point\n",
    "                    d_click = self.get_average_depth(depth_frame, cx, cy, h, w)\n",
    "                    cv2.drawMarker(color_image, (cx, cy), (0, 0, 255), cv2.MARKER_CROSS, 20, 2)\n",
    "                    if d_click > 0:\n",
    "                        cv2.putText(color_image, f\"{d_click:.3f}m\", (cx + 10, cy - 5), 0, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'): break\n",
    "                elif key == ord('s') and current_landmarks:\n",
    "                    self.show_3d_snapshot(depth_frame, color_frame, current_landmarks)\n",
    "                elif key == ord('c'):\n",
    "                    self.clicked_point = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "        finally:\n",
    "            if pipeline_started: self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = RealSenseFaceScanner()\n",
    "    scanner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eab49fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> HƯỚNG DẪN: Distance màu Xanh (0.5m) để đạt độ chính xác Milimet.\n",
      "[Mouse Event] Tọa độ chọn: (394, 254)\n",
      "[Mouse Event] Tọa độ chọn: (383, 202)\n",
      "[Mouse Event] Tọa độ chọn: (437, 212)\n",
      "[Mouse Event] Tọa độ chọn: (363, 156)\n",
      "[Mouse Event] Tọa độ chọn: (379, 150)\n",
      "[Mouse Event] Tọa độ chọn: (344, 120)\n",
      "[Mouse Event] Tọa độ chọn: (337, 121)\n",
      "[Mouse Event] Tọa độ chọn: (330, 121)\n",
      "[Mouse Event] Tọa độ chọn: (342, 109)\n",
      "[Mouse Event] Tọa độ chọn: (347, 145)\n",
      "[Mouse Event] Tọa độ chọn: (350, 139)\n",
      "[Mouse Event] Tọa độ chọn: (311, 77)\n",
      "[Mouse Event] Tọa độ chọn: (314, 78)\n",
      "[Mouse Event] Tọa độ chọn: (501, 213)\n",
      "[Mouse Event] Tọa độ chọn: (287, 276)\n",
      "[Mouse Event] Tọa độ chọn: (590, 67)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 260\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    259\u001b[0m     scanner \u001b[38;5;241m=\u001b[39m RealSenseFaceScanner()\n\u001b[1;32m--> 260\u001b[0m     \u001b[43mscanner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 245\u001b[0m, in \u001b[0;36mRealSenseFaceScanner.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    241\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mputText(color_image, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDepth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md_click\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m, (cx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m10\u001b[39m, cy \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m5\u001b[39m), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0.6\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    243\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(window_name, color_image)\n\u001b[1;32m--> 245\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m): \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m current_landmarks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "class RealSenseFaceScanner:\n",
    "    def __init__(self):\n",
    "        # 1. Khởi tạo MediaPipe Face Mesh (Refine landmarks để lấy vùng mắt/môi chuẩn)\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.6\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.FACEMESH_TESSELATION = mp.solutions.face_mesh.FACEMESH_TESSELATION\n",
    "\n",
    "        # 2. Khởi tạo RealSense D455\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        # D455 chạy ổn định nhất ở 640x480 để giảm nhiễu mép\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # 3. Các bộ lọc xử lý nhiễu\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.hole_filling = rs.hole_filling_filter(2) \n",
    "\n",
    "        # [UPDATE] Các landmark quan trọng cho đo đạc sinh trắc học (mm accuracy)\n",
    "        self.key_landmarks = {\n",
    "            1: 'nose_tip',\n",
    "            10: 'forehead',\n",
    "            152: 'chin',\n",
    "            129: 'left_nose_wing',\n",
    "            358: 'right_nose_wing',\n",
    "            468: 'right_iris',\n",
    "            473: 'left_iris',\n",
    "            50: 'left_cheek',\n",
    "            280: 'right_cheek',\n",
    "            234: 'left_ear',\n",
    "            454: 'right_ear'\n",
    "        }\n",
    "\n",
    "        self.clicked_point = None\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\" Xử lý sự kiện click chuột để lấy tọa độ pixel \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.clicked_point = (x, y)\n",
    "            print(f\"[Mouse Event] Tọa độ chọn: ({x}, {y})\")\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, h, w, window_size=5):\n",
    "        \"\"\" Tính độ sâu trung bình trong vùng 5x5 để đảm bảo độ chính xác milimet \"\"\"\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < w and 0 <= ny < h:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0: depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def show_3d_snapshot(self, depth_frame, color_frame, face_landmarks):\n",
    "        \"\"\" PHIÊN BẢN TỐI ƯU CHO MESHLAB VỚI MẶT NẠ LANDMARK \"\"\"\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"[3D SNAPSHOT] ĐANG TẠO MESH CHUẨN MESHLAB...\")\n",
    "            \n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            h, w = color_image.shape[:2]\n",
    "            color_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            # TẠO MẶT NẠ (MASK) TỪ LANDMARKS\n",
    "            face_oval_indices = [\n",
    "                10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, \n",
    "                397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, \n",
    "                172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109\n",
    "            ]\n",
    "            points = []\n",
    "            for idx in face_oval_indices:\n",
    "                lm = face_landmarks.landmark[idx]\n",
    "                points.append([int(lm.x * w), int(lm.y * h)])\n",
    "            \n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [np.array(points)], 255)\n",
    "\n",
    "            pc = rs.pointcloud()\n",
    "            pc.map_to(color_frame)\n",
    "            points_3d_all = pc.calculate(depth_frame)\n",
    "            v = points_3d_all.get_vertices()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(h, w, 3)\n",
    "            \n",
    "            valid_indices = np.where((mask > 0) & (verts[:, :, 2] > 0.1) & (verts[:, :, 2] < 1.0))\n",
    "            final_verts = verts[valid_indices]\n",
    "            final_colors = color_rgb[valid_indices]\n",
    "\n",
    "            if len(final_verts) < 2000:\n",
    "                print(\"[LỖI] Không đủ dữ liệu mặt.\")\n",
    "                return\n",
    "\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(final_verts)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(final_colors)\n",
    "\n",
    "            pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=1.5)\n",
    "            pcd.translate(-pcd.get_center())\n",
    "            R = pcd.get_rotation_matrix_from_axis_angle([np.pi, 0, 0])\n",
    "            pcd.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.03, max_nn=30))\n",
    "            pcd.orient_normals_towards_camera_location(camera_location=[0, 0, 10])\n",
    "\n",
    "            distances = pcd.compute_nearest_neighbor_distance()\n",
    "            avg_dist = np.mean(distances)\n",
    "            radius = 2 * avg_dist\n",
    "            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "                pcd, o3d.utility.DoubleVector([radius, radius * 2])\n",
    "            )\n",
    "            mesh.vertex_colors = pcd.colors\n",
    "\n",
    "            filename = \"face_mesh_biometrics.ply\"\n",
    "            o3d.io.write_triangle_mesh(filename, mesh)\n",
    "            full_path = os.path.abspath(filename)\n",
    "            print(f\"[THÀNH CÔNG] File đã lưu tại: {full_path}\")\n",
    "            os.startfile(full_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LỖI] {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "            pipeline_started = True\n",
    "            \n",
    "            device = profile.get_device()\n",
    "            depth_sensor = device.query_sensors()[0]\n",
    "            if depth_sensor.supports(rs.option.visual_preset):\n",
    "                depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "\n",
    "            window_name = '3D BIOMETRIC SCANNER - D455'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            current_landmarks = None\n",
    "\n",
    "            print(\"\\n>>> HƯỚNG DẪN: Distance màu Xanh (0.5m) để đạt độ chính xác Milimet.\")\n",
    "\n",
    "            while True:\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "                if not depth_frame or not color_frame: continue\n",
    "\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame).as_depth_frame()\n",
    "\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                h, w = color_image.shape[:2]\n",
    "                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "                results = self.mp_face_mesh.process(rgb_image)\n",
    "\n",
    "                # Vẽ khung Dashboard bán trong suốt\n",
    "                overlay = color_image.copy()\n",
    "                cv2.rectangle(overlay, (5, 5), (280, 240), (0, 0, 0), -1)\n",
    "                cv2.addWeighted(overlay, 0.6, color_image, 0.4, 0, color_image)\n",
    "\n",
    "                # Khoảng cách trung tâm\n",
    "                d_center = self.get_average_depth(depth_frame, w//2, h//2, h, w)\n",
    "                color_status = (0, 255, 0) if 0.45 <= d_center <= 0.6 else (0, 0, 255)\n",
    "                cv2.putText(color_image, f\"Distance: {d_center:.2f}m\", (15, 30), 0, 0.6, color_status, 2)\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    current_landmarks = results.multi_face_landmarks[0]\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        image=color_image, landmark_list=current_landmarks,\n",
    "                        connections=self.FACEMESH_TESSELATION,\n",
    "                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                    )\n",
    "\n",
    "                    color_intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "                    points_3d = {}\n",
    "                    for idx, name in self.key_landmarks.items():\n",
    "                        lm = current_landmarks.landmark[idx]\n",
    "                        u, v = int(lm.x * w), int(lm.y * h)\n",
    "                        depth = self.get_average_depth(depth_frame, u, v, h, w)\n",
    "                        if depth > 0:\n",
    "                            pt = rs.rs2_deproject_pixel_to_point(color_intrinsics, [u, v], depth)\n",
    "                            points_3d[name] = np.array(pt)\n",
    "\n",
    "                    # LOGIC ĐO ĐẠC CHI TIẾT (mm/cm)\n",
    "                    y_off = 65\n",
    "                    txt_color = (255, 255, 255)\n",
    "                    \n",
    "                    # 1. IPD (mm)\n",
    "                    if 'left_iris' in points_3d and 'right_iris' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_iris'] - points_3d['right_iris']) * 1000\n",
    "                        cv2.putText(color_image, f\"IPD: {val:.1f} mm\", (15, y_off), 0, 0.55, (255, 255, 0), 1)\n",
    "                        y_off += 25\n",
    "                    \n",
    "                    # 2. Face Height (cm)\n",
    "                    if 'forehead' in points_3d and 'chin' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['forehead'] - points_3d['chin']) * 100\n",
    "                        cv2.putText(color_image, f\"Height: {val:.1f} cm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    # 3. Face Width (mm) - Ear to Ear\n",
    "                    if 'left_ear' in points_3d and 'right_ear' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_ear'] - points_3d['right_ear']) * 1000\n",
    "                        cv2.putText(color_image, f\"Face Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    # 4. Cheek Width (mm)\n",
    "                    if 'left_cheek' in points_3d and 'right_cheek' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_cheek'] - points_3d['right_cheek']) * 1000\n",
    "                        cv2.putText(color_image, f\"Cheek Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    # 5. Nose Width (mm)\n",
    "                    if 'left_nose_wing' in points_3d and 'right_nose_wing' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_nose_wing'] - points_3d['right_nose_wing']) * 1000\n",
    "                        cv2.putText(color_image, f\"Nose Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                # Click chuột đo tự do\n",
    "                if self.clicked_point:\n",
    "                    cx, cy = self.clicked_point\n",
    "                    d_click = self.get_average_depth(depth_frame, cx, cy, h, w)\n",
    "                    cv2.drawMarker(color_image, (cx, cy), (0, 0, 255), cv2.MARKER_CROSS, 20, 2)\n",
    "                    if d_click > 0:\n",
    "                        cv2.putText(color_image, f\"Depth: {d_click:.3f}m\", (cx + 10, cy - 5), 0, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'): break\n",
    "                elif key == ord('s') and current_landmarks:\n",
    "                    self.show_3d_snapshot(depth_frame, color_frame, current_landmarks)\n",
    "                elif key == ord('c'):\n",
    "                    self.clicked_point = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "        finally:\n",
    "            if pipeline_started: self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = RealSenseFaceScanner()\n",
    "    scanner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be44ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> HƯỚNG DẪN: Distance màu Xanh (0.5m) để đạt độ chính xác Milimet.\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import open3d as o3d\n",
    "import os\n",
    "\n",
    "class RealSenseFaceScanner:\n",
    "    def __init__(self):\n",
    "        # 1. Khởi tạo MediaPipe Face Mesh (Refine landmarks để lấy vùng mắt/môi chuẩn)\n",
    "        self.mp_face_mesh = mp.solutions.face_mesh.FaceMesh(\n",
    "            static_image_mode=False,\n",
    "            max_num_faces=1,\n",
    "            refine_landmarks=True,\n",
    "            min_detection_confidence=0.6,\n",
    "            min_tracking_confidence=0.6\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        self.FACEMESH_TESSELATION = mp.solutions.face_mesh.FACEMESH_TESSELATION\n",
    "\n",
    "        # 2. Khởi tạo RealSense D455\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        # D455 chạy ổn định nhất ở 640x480 để giảm nhiễu mép\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # 3. Các bộ lọc xử lý nhiễu\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.hole_filling = rs.hole_filling_filter(2) \n",
    "\n",
    "        # Các landmark quan trọng cho đo đạc sinh trắc học (mm accuracy)\n",
    "        self.key_landmarks = {\n",
    "            1: 'nose_tip',\n",
    "            10: 'forehead',\n",
    "            152: 'chin',\n",
    "            129: 'left_nose_wing',\n",
    "            358: 'right_nose_wing',\n",
    "            468: 'right_iris',\n",
    "            473: 'left_iris',\n",
    "            50: 'left_cheek',\n",
    "            280: 'right_cheek',\n",
    "            234: 'left_ear',\n",
    "            454: 'right_ear'\n",
    "        }\n",
    "\n",
    "        self.clicked_point = None\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        \"\"\" Xử lý sự kiện click chuột để lấy tọa độ pixel \"\"\"\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.clicked_point = (x, y)\n",
    "            print(f\"[Mouse Event] Tọa độ chọn: ({x}, {y})\")\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, h, w, window_size=5):\n",
    "        \"\"\" Tính độ sâu trung bình trong vùng 5x5 để đảm bảo độ chính xác milimet \"\"\"\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < w and 0 <= ny < h:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0: depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def show_3d_snapshot(self, depth_frame, color_frame, face_landmarks):\n",
    "        \"\"\" PHIÊN BẢN TỐI ƯU CHO MESHLAB VỚI MẶT NẠ LANDMARK \"\"\"\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\"*50)\n",
    "            print(\"[3D SNAPSHOT] ĐANG TẠO MESH CHUẨN MESHLAB...\")\n",
    "            \n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            h, w = color_image.shape[:2]\n",
    "            color_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            # TẠO MẶT NẠ (MASK) TỪ LANDMARKS\n",
    "            face_oval_indices = [\n",
    "                10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, \n",
    "                397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, \n",
    "                172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109\n",
    "            ]\n",
    "            points = []\n",
    "            for idx in face_oval_indices:\n",
    "                lm = face_landmarks.landmark[idx]\n",
    "                points.append([int(lm.x * w), int(lm.y * h)])\n",
    "            \n",
    "            mask = np.zeros((h, w), dtype=np.uint8)\n",
    "            cv2.fillPoly(mask, [np.array(points)], 255)\n",
    "\n",
    "            pc = rs.pointcloud()\n",
    "            pc.map_to(color_frame)\n",
    "            points_3d_all = pc.calculate(depth_frame)\n",
    "            v = points_3d_all.get_vertices()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(h, w, 3)\n",
    "            \n",
    "            valid_indices = np.where((mask > 0) & (verts[:, :, 2] > 0.1) & (verts[:, :, 2] < 1.0))\n",
    "            final_verts = verts[valid_indices]\n",
    "            final_colors = color_rgb[valid_indices]\n",
    "\n",
    "            if len(final_verts) < 2000:\n",
    "                print(\"[LỖI] Không đủ dữ liệu mặt.\")\n",
    "                return\n",
    "\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(final_verts)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(final_colors)\n",
    "\n",
    "            pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=1.5)\n",
    "            pcd.translate(-pcd.get_center())\n",
    "            R = pcd.get_rotation_matrix_from_axis_angle([np.pi, 0, 0])\n",
    "            pcd.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "            pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.03, max_nn=30))\n",
    "            pcd.orient_normals_towards_camera_location(camera_location=[0, 0, 10])\n",
    "\n",
    "            distances = pcd.compute_nearest_neighbor_distance()\n",
    "            avg_dist = np.mean(distances)\n",
    "            radius = 2 * avg_dist\n",
    "            mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(\n",
    "                pcd, o3d.utility.DoubleVector([radius, radius * 2])\n",
    "            )\n",
    "            mesh.vertex_colors = pcd.colors\n",
    "\n",
    "            filename = \"face_mesh_biometrics.ply\"\n",
    "            o3d.io.write_triangle_mesh(filename, mesh)\n",
    "            full_path = os.path.abspath(filename)\n",
    "            print(f\"[THÀNH CÔNG] File đã lưu tại: {full_path}\")\n",
    "            os.startfile(full_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[LỖI] {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "            pipeline_started = True\n",
    "            \n",
    "            device = profile.get_device()\n",
    "            depth_sensor = device.query_sensors()[0]\n",
    "            if depth_sensor.supports(rs.option.visual_preset):\n",
    "                depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "\n",
    "            window_name = '3D BIOMETRIC SCANNER - D455'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            current_landmarks = None\n",
    "\n",
    "            print(\"\\n>>> HƯỚNG DẪN: Distance màu Xanh (0.5m) để đạt độ chính xác Milimet.\")\n",
    "\n",
    "            while True:\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned_frames = self.align.process(frames)\n",
    "                depth_frame = aligned_frames.get_depth_frame()\n",
    "                color_frame = aligned_frames.get_color_frame()\n",
    "\n",
    "                if not depth_frame or not color_frame: continue\n",
    "\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame).as_depth_frame()\n",
    "\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                h, w = color_image.shape[:2]\n",
    "                rgb_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)\n",
    "                results = self.mp_face_mesh.process(rgb_image)\n",
    "\n",
    "                # Vẽ khung Dashboard bán trong suốt cho thông số\n",
    "                overlay = color_image.copy()\n",
    "                cv2.rectangle(overlay, (5, 5), (280, 240), (0, 0, 0), -1)\n",
    "                cv2.addWeighted(overlay, 0.6, color_image, 0.4, 0, color_image)\n",
    "\n",
    "                # Khoảng cách trung tâm\n",
    "                d_center = self.get_average_depth(depth_frame, w//2, h//2, h, w)\n",
    "                color_status = (0, 255, 0) if 0.45 <= d_center <= 0.6 else (0, 0, 255)\n",
    "                cv2.putText(color_image, f\"Distance: {d_center:.2f}m\", (15, 30), 0, 0.6, color_status, 2)\n",
    "\n",
    "                if results.multi_face_landmarks:\n",
    "                    current_landmarks = results.multi_face_landmarks[0]\n",
    "                    \n",
    "                    # [UPDATE] ẨN CHẤM ĐỎ: Sử dụng landmark_drawing_spec với độ dày và bán kính = 0\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        image=color_image, \n",
    "                        landmark_list=current_landmarks,\n",
    "                        connections=self.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=None, # MediaPipe mặc định vẽ chấm nếu để None, ta sẽ ghi đè bên dưới\n",
    "                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                    )\n",
    "                    # Một số phiên bản yêu cầu tham số landmark_drawing_spec cụ thể để ẩn điểm:\n",
    "                    # Để ẩn hẳn các chấm đỏ, ta có thể dùng DrawingSpec với circle_radius=0\n",
    "                    invisible_spec = self.mp_drawing.DrawingSpec(thickness=0, circle_radius=0)\n",
    "                    self.mp_drawing.draw_landmarks(\n",
    "                        image=color_image,\n",
    "                        landmark_list=current_landmarks,\n",
    "                        connections=self.FACEMESH_TESSELATION,\n",
    "                        landmark_drawing_spec=invisible_spec,\n",
    "                        connection_drawing_spec=self.mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=1)\n",
    "                    )\n",
    "\n",
    "                    color_intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "                    points_3d = {}\n",
    "                    for idx, name in self.key_landmarks.items():\n",
    "                        lm = current_landmarks.landmark[idx]\n",
    "                        u, v = int(lm.x * w), int(lm.y * h)\n",
    "                        depth = self.get_average_depth(depth_frame, u, v, h, w)\n",
    "                        if depth > 0:\n",
    "                            pt = rs.rs2_deproject_pixel_to_point(color_intrinsics, [u, v], depth)\n",
    "                            points_3d[name] = np.array(pt)\n",
    "\n",
    "                    # LOGIC ĐO ĐẠC CHI TIẾT (mm/cm)\n",
    "                    y_off = 65\n",
    "                    txt_color = (255, 255, 255)\n",
    "                    \n",
    "                    if 'left_iris' in points_3d and 'right_iris' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_iris'] - points_3d['right_iris']) * 1000\n",
    "                        cv2.putText(color_image, f\"IPD: {val:.1f} mm\", (15, y_off), 0, 0.55, (255, 255, 0), 1)\n",
    "                        y_off += 25\n",
    "                    \n",
    "                    if 'forehead' in points_3d and 'chin' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['forehead'] - points_3d['chin']) * 100\n",
    "                        cv2.putText(color_image, f\"Height: {val:.1f} cm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    if 'left_ear' in points_3d and 'right_ear' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_ear'] - points_3d['right_ear']) * 1000\n",
    "                        cv2.putText(color_image, f\"Face Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    if 'left_cheek' in points_3d and 'right_cheek' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_cheek'] - points_3d['right_cheek']) * 1000\n",
    "                        cv2.putText(color_image, f\"Cheek Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                    if 'left_nose_wing' in points_3d and 'right_nose_wing' in points_3d:\n",
    "                        val = np.linalg.norm(points_3d['left_nose_wing'] - points_3d['right_nose_wing']) * 1000\n",
    "                        cv2.putText(color_image, f\"Nose Width: {val:.1f} mm\", (15, y_off), 0, 0.55, txt_color, 1)\n",
    "                        y_off += 25\n",
    "\n",
    "                # Click chuột đo tự do\n",
    "                if self.clicked_point:\n",
    "                    cx, cy = self.clicked_point\n",
    "                    d_click = self.get_average_depth(depth_frame, cx, cy, h, w)\n",
    "                    cv2.drawMarker(color_image, (cx, cy), (0, 0, 255), cv2.MARKER_CROSS, 20, 2)\n",
    "                    if d_click > 0:\n",
    "                        cv2.putText(color_image, f\"Depth: {d_click:.3f}m\", (cx + 10, cy - 5), 0, 0.6, (0, 255, 255), 2)\n",
    "\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'): break\n",
    "                elif key == ord('s') and current_landmarks:\n",
    "                    self.show_3d_snapshot(depth_frame, color_frame, current_landmarks)\n",
    "                elif key == ord('c'):\n",
    "                    self.clicked_point = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "        finally:\n",
    "            if pipeline_started: self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scanner = RealSenseFaceScanner()\n",
    "    scanner.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300ac97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[YOLO-SEG] Đang tải model...\n",
      "[YOLO-SEG] Model 'yolov8n-seg.pt' đã sẵn sàng!\n",
      "\n",
      "=======================================================\n",
      "  YOLOv8-Seg + RealSense D455 — 3D Object Scanner\n",
      "=======================================================\n",
      "  Click chuột  → Chọn vật thể\n",
      "  [s]          → Xuất 3D mesh (.ply)\n",
      "  [m]          → Bật/tắt lưới mesh wireframe\n",
      "  [+/-]        → Tăng/giảm mật độ lưới\n",
      "  [c]          → Xoá lựa chọn\n",
      "  [q]          → Thoát\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import os\n",
    "from scipy.spatial import Delaunay\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "class RealSenseYOLOScanner:\n",
    "    def __init__(self, model_name=\"yolov8n-seg.pt\", confidence=0.5):\n",
    "        \"\"\"\n",
    "        model_name: YOLOv8-seg model (yolov8n-seg / s-seg / m-seg / l-seg / x-seg .pt)\n",
    "                    PHẢI dùng model -seg để có segmentation mask!\n",
    "        confidence: Ngưỡng confidence tối thiểu\n",
    "        \"\"\"\n",
    "        # ========== YOLOv8-Seg ==========\n",
    "        print(\"[YOLO-SEG] Đang tải model...\")\n",
    "        self.model = YOLO(model_name)\n",
    "        self.confidence = confidence\n",
    "        print(f\"[YOLO-SEG] Model '{model_name}' đã sẵn sàng!\")\n",
    "\n",
    "        # ========== RealSense D455 ==========\n",
    "        self.pipeline = rs.pipeline()\n",
    "        self.config = rs.config()\n",
    "        self.config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "        self.config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "        self.align = rs.align(rs.stream.color)\n",
    "\n",
    "        # Bộ lọc nhiễu depth\n",
    "        self.spatial = rs.spatial_filter()\n",
    "        self.temporal = rs.temporal_filter()\n",
    "        self.hole_filling = rs.hole_filling_filter(2)\n",
    "\n",
    "        # Khoảng depth quan tâm (mét)\n",
    "        self.min_depth = 0.15\n",
    "        self.max_depth = 2.0\n",
    "\n",
    "        # Poisson reconstruction depth\n",
    "        self.poisson_depth = 9\n",
    "\n",
    "        # Mesh wireframe settings\n",
    "        self.mesh_grid_step = 8       # Khoảng cách giữa các điểm lưới (pixel), nhỏ hơn = dày hơn\n",
    "        self.mesh_line_thickness = 1  # Độ dày đường lưới\n",
    "        self.show_mesh_wireframe = True  # Bật/tắt lưới mesh\n",
    "\n",
    "        # State\n",
    "        self.clicked_point = None\n",
    "        self.selected_object = None\n",
    "\n",
    "        # Màu cố định cho từng class\n",
    "        np.random.seed(42)\n",
    "        self.class_colors = {\n",
    "            i: tuple(int(c) for c in np.random.randint(80, 255, 3))\n",
    "            for i in range(80)\n",
    "        }\n",
    "\n",
    "    # ==========================================\n",
    "    #  VẼ LƯỚI MESH WIREFRAME LÊN VẬT THỂ\n",
    "    #  (Tương tự FACEMESH_TESSELATION của MediaPipe)\n",
    "    # ==========================================\n",
    "    def draw_mesh_wireframe(self, image, det, depth_frame, h, w):\n",
    "        \"\"\"\n",
    "        Vẽ lưới tam giác (Delaunay tesselation) lên vật thể trong ảnh camera.\n",
    "        Giống cách MediaPipe vẽ FACEMESH_TESSELATION cho khuôn mặt.\n",
    "\n",
    "        Logic:\n",
    "        1. Sample đều các điểm trong segmentation mask\n",
    "        2. Lọc điểm có depth hợp lệ\n",
    "        3. Delaunay triangulation trên toạ độ 2D\n",
    "        4. Vẽ các cạnh tam giác, tô màu theo depth\n",
    "        \"\"\"\n",
    "        seg_mask = det['seg_mask']\n",
    "        if seg_mask is None:\n",
    "            return\n",
    "\n",
    "        color = self.class_colors.get(det['cls_id'], (0, 255, 0))\n",
    "        bx, by, bw, bh = det['bbox']\n",
    "        step = self.mesh_grid_step\n",
    "\n",
    "        # === 1. Sample điểm đều trong mask ===\n",
    "        points_2d = []\n",
    "        points_depth = []\n",
    "\n",
    "        for py in range(by, min(by + bh, h), step):\n",
    "            for px in range(bx, min(bx + bw, w), step):\n",
    "                if seg_mask[py, px] > 0:\n",
    "                    d = depth_frame.get_distance(px, py)\n",
    "                    if self.min_depth < d < self.max_depth:\n",
    "                        points_2d.append([px, py])\n",
    "                        points_depth.append(d)\n",
    "\n",
    "        # Thêm các điểm contour để lưới bám sát viền vật thể\n",
    "        contours, _ = cv2.findContours(seg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            for i in range(0, len(cnt), max(1, len(cnt) // 60)):\n",
    "                px, py = cnt[i][0]\n",
    "                if 0 <= px < w and 0 <= py < h:\n",
    "                    d = depth_frame.get_distance(int(px), int(py))\n",
    "                    if self.min_depth < d < self.max_depth:\n",
    "                        points_2d.append([int(px), int(py)])\n",
    "                        points_depth.append(d)\n",
    "\n",
    "        if len(points_2d) < 10:\n",
    "            return\n",
    "\n",
    "        points_2d = np.array(points_2d)\n",
    "        points_depth = np.array(points_depth)\n",
    "\n",
    "        # === 2. Delaunay triangulation (giống tesselation) ===\n",
    "        try:\n",
    "            tri = Delaunay(points_2d)\n",
    "        except Exception:\n",
    "            return\n",
    "\n",
    "        # === 3. Tính depth range để map màu ===\n",
    "        d_min = det['min_depth'] if det['min_depth'] > 0 else points_depth.min()\n",
    "        d_max = det['max_depth'] if det['max_depth'] > 0 else points_depth.max()\n",
    "        d_range = d_max - d_min if d_max > d_min else 0.01\n",
    "\n",
    "        # === 4. Vẽ các tam giác ===\n",
    "        for simplex in tri.simplices:\n",
    "            p0 = points_2d[simplex[0]]\n",
    "            p1 = points_2d[simplex[1]]\n",
    "            p2 = points_2d[simplex[2]]\n",
    "\n",
    "            # Kiểm tra tâm tam giác nằm trong mask (loại bỏ tam giác ngoài vật thể)\n",
    "            cx_tri = int((p0[0] + p1[0] + p2[0]) / 3)\n",
    "            cy_tri = int((p0[1] + p1[1] + p2[1]) / 3)\n",
    "            if 0 <= cx_tri < w and 0 <= cy_tri < h:\n",
    "                if seg_mask[cy_tri, cx_tri] == 0:\n",
    "                    continue\n",
    "\n",
    "            # Depth trung bình của tam giác → màu\n",
    "            avg_d = (points_depth[simplex[0]] + points_depth[simplex[1]] + points_depth[simplex[2]]) / 3\n",
    "            t = np.clip((avg_d - d_min) / d_range, 0, 1)\n",
    "\n",
    "            # Gradient màu: gần (xanh lá sáng) → xa (xanh lá tối)\n",
    "            r = int(color[0] * (1 - t * 0.6))\n",
    "            g = int(color[1] * (1 - t * 0.6))\n",
    "            b = int(color[2] * (1 - t * 0.6))\n",
    "            line_color = (r, g, b)\n",
    "\n",
    "            # Vẽ 3 cạnh tam giác\n",
    "            pts = [tuple(p0), tuple(p1), tuple(p2)]\n",
    "            cv2.line(image, pts[0], pts[1], line_color, self.mesh_line_thickness, cv2.LINE_AA)\n",
    "            cv2.line(image, pts[1], pts[2], line_color, self.mesh_line_thickness, cv2.LINE_AA)\n",
    "            cv2.line(image, pts[2], pts[0], line_color, self.mesh_line_thickness, cv2.LINE_AA)\n",
    "\n",
    "    def mouse_callback(self, event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            self.clicked_point = (x, y)\n",
    "            if hasattr(self, '_current_detections'):\n",
    "                for det in self._current_detections:\n",
    "                    if det['seg_mask'] is not None and det['seg_mask'][y, x] > 0:\n",
    "                        self.selected_object = det\n",
    "                        print(f\"[SELECT] Đã chọn: {det['label']} \"\n",
    "                              f\"(conf: {det['conf']:.0%}, depth: {det['avg_depth']:.2f}m, \"\n",
    "                              f\"mask pixels: {det['mask_area']})\")\n",
    "                        return\n",
    "                    bx, by2, bw, bh = det['bbox']\n",
    "                    if bx <= x <= bx + bw and by2 <= y <= by2 + bh:\n",
    "                        self.selected_object = det\n",
    "                        print(f\"[SELECT] Đã chọn (bbox): {det['label']}\")\n",
    "                        return\n",
    "            print(f\"[Mouse] ({x}, {y}) - Không trúng vật thể nào\")\n",
    "            self.selected_object = None\n",
    "\n",
    "    def get_average_depth(self, depth_frame, x, y, h, w, window_size=5):\n",
    "        depths = []\n",
    "        half = window_size // 2\n",
    "        for dy in range(-half, half + 1):\n",
    "            for dx in range(-half, half + 1):\n",
    "                nx, ny = x + dx, y + dy\n",
    "                if 0 <= nx < w and 0 <= ny < h:\n",
    "                    d = depth_frame.get_distance(nx, ny)\n",
    "                    if d > 0:\n",
    "                        depths.append(d)\n",
    "        return np.mean(depths) if depths else 0.0\n",
    "\n",
    "    def detect_objects(self, color_image, depth_frame, h, w):\n",
    "        results = self.model(color_image, conf=self.confidence, verbose=False)\n",
    "        detections = []\n",
    "\n",
    "        if not results or len(results) == 0:\n",
    "            return detections\n",
    "\n",
    "        result = results[0]\n",
    "        has_masks = result.masks is not None and len(result.masks) > 0\n",
    "\n",
    "        for i, box in enumerate(result.boxes):\n",
    "            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)\n",
    "            conf = float(box.conf[0])\n",
    "            cls_id = int(box.cls[0])\n",
    "            label = self.model.names[cls_id]\n",
    "\n",
    "            bx, by = max(0, x1), max(0, y1)\n",
    "            bw = min(x2, w) - bx\n",
    "            bh = min(y2, h) - by\n",
    "\n",
    "            seg_mask = None\n",
    "            mask_area = 0\n",
    "\n",
    "            if has_masks:\n",
    "                raw_mask = result.masks.data[i].cpu().numpy()\n",
    "                seg_mask = cv2.resize(raw_mask, (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "                seg_mask = (seg_mask > 0.5).astype(np.uint8) * 255\n",
    "                mask_area = int(np.sum(seg_mask > 0))\n",
    "            else:\n",
    "                seg_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "                seg_mask[by:by + bh, bx:bx + bw] = 255\n",
    "                mask_area = bw * bh\n",
    "\n",
    "            depths = []\n",
    "            mask_coords = np.where(seg_mask > 0)\n",
    "            step = max(1, len(mask_coords[0]) // 500)\n",
    "            for idx in range(0, len(mask_coords[0]), step):\n",
    "                py, px = mask_coords[0][idx], mask_coords[1][idx]\n",
    "                d = depth_frame.get_distance(int(px), int(py))\n",
    "                if self.min_depth < d < self.max_depth:\n",
    "                    depths.append(d)\n",
    "\n",
    "            if depths:\n",
    "                avg_depth = float(np.mean(depths))\n",
    "                min_depth = float(np.min(depths))\n",
    "                max_depth = float(np.max(depths))\n",
    "            else:\n",
    "                avg_depth = min_depth = max_depth = 0.0\n",
    "\n",
    "            detections.append({\n",
    "                'bbox': (bx, by, bw, bh),\n",
    "                'conf': conf,\n",
    "                'cls_id': cls_id,\n",
    "                'label': label,\n",
    "                'seg_mask': seg_mask,\n",
    "                'mask_area': mask_area,\n",
    "                'avg_depth': avg_depth,\n",
    "                'min_depth': min_depth,\n",
    "                'max_depth': max_depth,\n",
    "            })\n",
    "\n",
    "        detections.sort(key=lambda d: d['conf'], reverse=True)\n",
    "        return detections\n",
    "\n",
    "    def compute_real_dimensions(self, det, depth_frame, color_frame):\n",
    "        intrinsics = color_frame.profile.as_video_stream_profile().intrinsics\n",
    "        x, y, bw, bh = det['bbox']\n",
    "\n",
    "        corners_2d = [(x, y), (x + bw, y), (x, y + bh), (x + bw, y + bh)]\n",
    "        corners_3d = []\n",
    "        for (cx, cy) in corners_2d:\n",
    "            cx = min(max(cx, 0), intrinsics.width - 1)\n",
    "            cy = min(max(cy, 0), intrinsics.height - 1)\n",
    "            d = depth_frame.get_distance(cx, cy)\n",
    "            if d <= 0 or d > self.max_depth:\n",
    "                d = det['avg_depth']\n",
    "            if d > 0:\n",
    "                pt = rs.rs2_deproject_pixel_to_point(intrinsics, [cx, cy], d)\n",
    "                corners_3d.append(np.array(pt))\n",
    "\n",
    "        if len(corners_3d) == 4:\n",
    "            w_mm = np.linalg.norm(corners_3d[1] - corners_3d[0]) * 1000\n",
    "            h_mm = np.linalg.norm(corners_3d[2] - corners_3d[0]) * 1000\n",
    "            t_mm = (det['max_depth'] - det['min_depth']) * 1000\n",
    "            return w_mm, h_mm, t_mm\n",
    "        return None, None, None\n",
    "\n",
    "    def export_object_3d(self, depth_frame, color_frame, det):\n",
    "        \"\"\"\n",
    "        Xuất 3D mesh chính xác theo hình dáng vật thể.\n",
    "        Dùng seg mask + Poisson reconstruction.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print(\"\\n\" + \"=\" * 55)\n",
    "            print(f\"[3D EXPORT] Đang tạo mesh cho: {det['label']}...\")\n",
    "            print(f\"            Mask pixels: {det['mask_area']}\")\n",
    "            print(f\"            Depth range: {det['min_depth']:.3f}m - {det['max_depth']:.3f}m\")\n",
    "\n",
    "            color_image = np.asanyarray(color_frame.get_data())\n",
    "            h, w = color_image.shape[:2]\n",
    "            color_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
    "\n",
    "            seg_mask = det['seg_mask']\n",
    "            if seg_mask is None or np.sum(seg_mask > 0) < 1000:\n",
    "                print(\"[LỖI] Mask quá nhỏ hoặc không có.\")\n",
    "                return\n",
    "\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "            seg_mask = cv2.morphologyEx(seg_mask, cv2.MORPH_CLOSE, kernel)\n",
    "            seg_mask = cv2.morphologyEx(seg_mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "            pc = rs.pointcloud()\n",
    "            pc.map_to(color_frame)\n",
    "            points_3d = pc.calculate(depth_frame)\n",
    "            v = points_3d.get_vertices()\n",
    "            verts = np.asanyarray(v).view(np.float32).reshape(h, w, 3)\n",
    "\n",
    "            d_margin = 0.03\n",
    "            d_min = max(self.min_depth, det['min_depth'] - d_margin)\n",
    "            d_max = min(self.max_depth, det['max_depth'] + d_margin)\n",
    "\n",
    "            valid = (\n",
    "                (seg_mask > 0) &\n",
    "                (verts[:, :, 2] > d_min) &\n",
    "                (verts[:, :, 2] < d_max) &\n",
    "                (verts[:, :, 0] != 0) &\n",
    "                (verts[:, :, 1] != 0)\n",
    "            )\n",
    "\n",
    "            valid_indices = np.where(valid)\n",
    "            final_verts = verts[valid_indices]\n",
    "            final_colors = color_rgb[valid_indices]\n",
    "\n",
    "            print(f\"            Valid 3D points: {len(final_verts)}\")\n",
    "            if len(final_verts) < 2000:\n",
    "                print(\"[LỖI] Không đủ điểm 3D. Đưa vật thể gần hơn (0.3-0.8m).\")\n",
    "                return\n",
    "\n",
    "            pcd = o3d.geometry.PointCloud()\n",
    "            pcd.points = o3d.utility.Vector3dVector(final_verts)\n",
    "            pcd.colors = o3d.utility.Vector3dVector(final_colors)\n",
    "\n",
    "            pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=1.5)\n",
    "            print(f\"            After outlier removal: {len(pcd.points)} points\")\n",
    "\n",
    "            pcd.translate(-pcd.get_center())\n",
    "            R = pcd.get_rotation_matrix_from_axis_angle([np.pi, 0, 0])\n",
    "            pcd.rotate(R, center=(0, 0, 0))\n",
    "\n",
    "            pcd.estimate_normals(\n",
    "                search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=50)\n",
    "            )\n",
    "            pcd.orient_normals_towards_camera_location(camera_location=[0, 0, -1])\n",
    "\n",
    "            print(f\"            Poisson reconstruction (depth={self.poisson_depth})...\")\n",
    "            mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
    "                pcd, depth=self.poisson_depth, width=0, scale=1.1, linear_fit=False\n",
    "            )\n",
    "\n",
    "            densities = np.asarray(densities)\n",
    "            density_threshold = np.quantile(densities, 0.05)\n",
    "            vertices_to_remove = densities < density_threshold\n",
    "            mesh.remove_vertices_by_mask(vertices_to_remove)\n",
    "\n",
    "            bbox = pcd.get_axis_aligned_bounding_box()\n",
    "            bbox_min = bbox.get_min_bound() - np.abs(bbox.get_min_bound()) * 0.05\n",
    "            bbox_max = bbox.get_max_bound() + np.abs(bbox.get_max_bound()) * 0.05\n",
    "            crop_bbox = o3d.geometry.AxisAlignedBoundingBox(bbox_min, bbox_max)\n",
    "            mesh = mesh.crop(crop_bbox)\n",
    "\n",
    "            # Map vertex colors từ point cloud\n",
    "            mesh.paint_uniform_color([0.7, 0.7, 0.7])\n",
    "            mesh_verts = np.asarray(mesh.vertices)\n",
    "            pcd_tree = o3d.geometry.KDTreeFlann(pcd)\n",
    "            vertex_colors = np.zeros_like(mesh_verts)\n",
    "            pcd_colors = np.asarray(pcd.colors)\n",
    "            for i in range(len(mesh_verts)):\n",
    "                _, idx, _ = pcd_tree.search_knn_vector_3d(mesh_verts[i], 1)\n",
    "                vertex_colors[i] = pcd_colors[idx[0]]\n",
    "            mesh.vertex_colors = o3d.utility.Vector3dVector(vertex_colors)\n",
    "\n",
    "            mesh = mesh.filter_smooth_laplacian(number_of_iterations=3)\n",
    "            mesh.compute_vertex_normals()\n",
    "\n",
    "            safe_label = det['label'].replace(' ', '_')\n",
    "            filename = f\"object_{safe_label}_{det['avg_depth']:.1f}m.ply\"\n",
    "            o3d.io.write_triangle_mesh(filename, mesh)\n",
    "            full_path = os.path.abspath(filename)\n",
    "\n",
    "            print(f\"\\n[THÀNH CÔNG] File: {full_path}\")\n",
    "            print(f\"             Label: {det['label']} ({det['conf']:.0%})\")\n",
    "            print(f\"             Vertices: {len(mesh.vertices)}\")\n",
    "            print(f\"             Triangles: {len(mesh.triangles)}\")\n",
    "\n",
    "            os.startfile(full_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "            print(f\"[LỖI] {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "    def run(self):\n",
    "        pipeline_started = False\n",
    "        try:\n",
    "            profile = self.pipeline.start(self.config)\n",
    "            pipeline_started = True\n",
    "\n",
    "            device = profile.get_device()\n",
    "            depth_sensor = device.query_sensors()[0]\n",
    "            if depth_sensor.supports(rs.option.visual_preset):\n",
    "                depth_sensor.set_option(rs.option.visual_preset, 4)\n",
    "\n",
    "            window_name = 'YOLOv8-Seg + RealSense 3D Scanner'\n",
    "            cv2.namedWindow(window_name)\n",
    "            cv2.setMouseCallback(window_name, self.mouse_callback)\n",
    "\n",
    "            print(\"\\n\" + \"=\" * 55)\n",
    "            print(\"  YOLOv8-Seg + RealSense D455 — 3D Object Scanner\")\n",
    "            print(\"=\" * 55)\n",
    "            print(\"  Click chuột  → Chọn vật thể\")\n",
    "            print(\"  [s]          → Xuất 3D mesh (.ply)\")\n",
    "            print(\"  [m]          → Bật/tắt lưới mesh wireframe\")\n",
    "            print(\"  [+/-]        → Tăng/giảm mật độ lưới\")\n",
    "            print(\"  [c]          → Xoá lựa chọn\")\n",
    "            print(\"  [q]          → Thoát\")\n",
    "            print(\"=\" * 55)\n",
    "\n",
    "            while True:\n",
    "                frames = self.pipeline.wait_for_frames()\n",
    "                aligned = self.align.process(frames)\n",
    "                depth_frame = aligned.get_depth_frame()\n",
    "                color_frame = aligned.get_color_frame()\n",
    "                if not depth_frame or not color_frame:\n",
    "                    continue\n",
    "\n",
    "                depth_frame = self.spatial.process(depth_frame)\n",
    "                depth_frame = self.temporal.process(depth_frame)\n",
    "                depth_frame = self.hole_filling.process(depth_frame).as_depth_frame()\n",
    "\n",
    "                color_image = np.asanyarray(color_frame.get_data())\n",
    "                h, w = color_image.shape[:2]\n",
    "\n",
    "                # ===== YOLO-SEG DETECT =====\n",
    "                detections = self.detect_objects(color_image, depth_frame, h, w)\n",
    "                self._current_detections = detections\n",
    "\n",
    "                # ===== DASHBOARD =====\n",
    "                overlay = color_image.copy()\n",
    "                panel_h = 55 + len(detections[:8]) * 22\n",
    "                cv2.rectangle(overlay, (5, 5), (370, max(65, panel_h)), (0, 0, 0), -1)\n",
    "                cv2.addWeighted(overlay, 0.65, color_image, 0.35, 0, color_image)\n",
    "\n",
    "                d_center = self.get_average_depth(depth_frame, w // 2, h // 2, h, w)\n",
    "                clr = (0, 255, 0) if 0.3 <= d_center <= 1.5 else (0, 0, 255)\n",
    "                cv2.putText(color_image, f\"Distance: {d_center:.2f}m\", (15, 28), 0, 0.6, clr, 2)\n",
    "\n",
    "                mesh_status = \"MESH ON\" if self.show_mesh_wireframe else \"MESH OFF\"\n",
    "                cv2.putText(color_image, f\"Objects: {len(detections)} | {mesh_status} (grid={self.mesh_grid_step}px)\",\n",
    "                            (15, 50), 0, 0.42, (0, 255, 255), 1)\n",
    "\n",
    "                # ===== VẼ LƯỚI MESH WIREFRAME + MASKS =====\n",
    "                for i, det in enumerate(detections):\n",
    "                    cls_id = det['cls_id']\n",
    "                    color = self.class_colors.get(cls_id, (0, 255, 0))\n",
    "                    bx, by, bw, bh = det['bbox']\n",
    "\n",
    "                    is_selected = (\n",
    "                        self.selected_object is not None and\n",
    "                        det['bbox'] == self.selected_object['bbox']\n",
    "                    )\n",
    "\n",
    "                    # ★ VẼ LƯỚI MESH WIREFRAME (giống Face Mesh tesselation) ★\n",
    "                    if self.show_mesh_wireframe and det['avg_depth'] > 0:\n",
    "                        self.draw_mesh_wireframe(color_image, det, depth_frame, h, w)\n",
    "\n",
    "                    # Bounding box\n",
    "                    thickness = 3 if is_selected else 1\n",
    "                    cv2.rectangle(color_image, (bx, by), (bx + bw, by + bh), color, thickness)\n",
    "\n",
    "                    if is_selected:\n",
    "                        cv2.rectangle(color_image, (bx - 2, by - 2),\n",
    "                                      (bx + bw + 2, by + bh + 2), (255, 255, 255), 1)\n",
    "\n",
    "                    # Label\n",
    "                    label_text = f\"{det['label']} {det['conf']:.0%}\"\n",
    "                    if det['avg_depth'] > 0:\n",
    "                        label_text += f\" {det['avg_depth']:.2f}m\"\n",
    "\n",
    "                    (tw, th_t), _ = cv2.getTextSize(label_text, 0, 0.5, 1)\n",
    "                    cv2.rectangle(color_image, (bx, by - th_t - 8),\n",
    "                                  (bx + tw + 4, by), color, -1)\n",
    "                    cv2.putText(color_image, label_text, (bx + 2, by - 5),\n",
    "                                0, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "                    # Kích thước thực\n",
    "                    rw, rh_mm, t_mm = self.compute_real_dimensions(det, depth_frame, color_frame)\n",
    "                    if rw is not None:\n",
    "                        dim_text = f\"{rw:.0f}x{rh_mm:.0f}mm\"\n",
    "                        if t_mm and t_mm > 3:\n",
    "                            dim_text += f\" D:{t_mm:.0f}mm\"\n",
    "                        cv2.putText(color_image, dim_text,\n",
    "                                    (bx, by + bh + 16), 0, 0.45, color, 1)\n",
    "\n",
    "                    # Dashboard\n",
    "                    if i < 8:\n",
    "                        info_y = 70 + i * 22\n",
    "                        prefix = \">>>\" if is_selected else f\" {i + 1}.\"\n",
    "                        info = f\"{prefix} {det['label']} ({det['conf']:.0%}) d={det['avg_depth']:.2f}m\"\n",
    "                        txt_clr = (255, 255, 255) if is_selected else (200, 200, 200)\n",
    "                        cv2.putText(color_image, info, (15, info_y), 0, 0.4, txt_clr, 1)\n",
    "\n",
    "                # Click marker\n",
    "                if self.clicked_point:\n",
    "                    cx, cy = self.clicked_point\n",
    "                    d_click = self.get_average_depth(depth_frame, cx, cy, h, w)\n",
    "                    cv2.drawMarker(color_image, (cx, cy), (0, 0, 255),\n",
    "                                   cv2.MARKER_CROSS, 20, 2)\n",
    "                    if d_click > 0:\n",
    "                        cv2.putText(color_image, f\"{d_click:.3f}m\",\n",
    "                                    (cx + 12, cy - 8), 0, 0.55, (0, 255, 255), 2)\n",
    "\n",
    "                cv2.imshow(window_name, color_image)\n",
    "\n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('s'):\n",
    "                    target = self.selected_object if self.selected_object else (\n",
    "                        detections[0] if detections else None\n",
    "                    )\n",
    "                    if target:\n",
    "                        self.export_object_3d(depth_frame, color_frame, target)\n",
    "                    else:\n",
    "                        print(\"[INFO] Không có vật thể nào để xuất.\")\n",
    "                elif key == ord('m'):\n",
    "                    self.show_mesh_wireframe = not self.show_mesh_wireframe\n",
    "                    print(f\"[MESH] Wireframe: {'ON' if self.show_mesh_wireframe else 'OFF'}\")\n",
    "                elif key == ord('+') or key == ord('='):\n",
    "                    self.mesh_grid_step = max(3, self.mesh_grid_step - 2)\n",
    "                    print(f\"[MESH] Grid step: {self.mesh_grid_step}px (dày hơn)\")\n",
    "                elif key == ord('-'):\n",
    "                    self.mesh_grid_step = min(30, self.mesh_grid_step + 2)\n",
    "                    print(f\"[MESH] Grid step: {self.mesh_grid_step}px (thưa hơn)\")\n",
    "                elif key == ord('c'):\n",
    "                    self.clicked_point = None\n",
    "                    self.selected_object = None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Lỗi: {e}\")\n",
    "        finally:\n",
    "            if pipeline_started:\n",
    "                self.pipeline.stop()\n",
    "            cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # yolov8n-seg.pt = nano   (~7MB,  nhanh, có seg mask)\n",
    "    # yolov8s-seg.pt = small  (~23MB, cân bằng)\n",
    "    # yolov8m-seg.pt = medium (~52MB, chính xác hơn)\n",
    "    # yolov8x-seg.pt = xlarge (~137MB, chính xác nhất, cần GPU)\n",
    "    scanner = RealSenseYOLOScanner(model_name=\"yolov8n-seg.pt\", confidence=0.45)\n",
    "    scanner.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63dbacee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type('yolov8n-seg.pt'): <class 'str'>\n",
      "Tồn tại: True\n",
      "Kích thước (bytes): 7071756\n",
      "Đường dẫn đầy đủ: d:\\FaceGrid3D\\yolov8n-seg.pt\n",
      "\n",
      "scanner.model (YOLO object) type: <class 'ultralytics.models.yolo.model.YOLO'>\n",
      "Underlying torch model type: <class 'ultralytics.nn.tasks.SegmentationModel'>\n",
      "\n",
      "--- Tóm tắt mô hình (repr) ---\n",
      "SegmentationModel(\n",
      "  (model): Sequential(\n",
      "    (0): Conv(\n",
      "      (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (1): Conv(\n",
      "      (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (2): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Conv(\n",
      "      (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (4): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Conv(\n",
      "      (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (6): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0-1): 2 x Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): Conv(\n",
      "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (8): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): SPPF(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (11): Concat()\n",
      "    (12): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "    (14): Concat()\n",
      "    (15): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (17): Concat()\n",
      "    (18): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (19): Conv(\n",
      "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (act): SiLU(inplace=True)\n",
      "    )\n",
      "    (20): Concat()\n",
      "    (21): C2f(\n",
      "      (cv1): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (cv2): Conv(\n",
      "        (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (act): SiLU(inplace=True)\n",
      "      )\n",
      "      (m): ModuleList(\n",
      "        (0): Bottleneck(\n",
      "          (cv1): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (cv2): Conv(\n",
      "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (22): Segment(\n",
      "      (cv2): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (cv3): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (dfl): DFL(\n",
      "        (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (proto): Proto(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (upsample): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "        (cv3): Conv(\n",
      "          (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): SiLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (cv4): ModuleList(\n",
      "        (0): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): Sequential(\n",
      "          (0): Conv(\n",
      "            (conv): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv(\n",
      "            (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "            (act): SiLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "--- Chi tiết kiến trúc từ torchinfo.summary ---\n",
      "\n",
      "Tổng tham số: 3,404,320, Trainable: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "# In ra type của chuỗi, thông tin file model và kiến trúc mô hình đã load (dùng scanner từ cell trước)\n",
    "model_path = 'yolov8n-seg.pt'\n",
    "print(\"type('yolov8n-seg.pt'):\", type(model_path))\n",
    "\n",
    "print(\"Tồn tại:\", os.path.exists(model_path))\n",
    "if os.path.exists(model_path):\n",
    "    print(\"Kích thước (bytes):\", os.path.getsize(model_path))\n",
    "    print(\"Đường dẫn đầy đủ:\", os.path.abspath(model_path))\n",
    "\n",
    "print(\"\\nscanner.model (YOLO object) type:\", type(scanner.model))\n",
    "try:\n",
    "    torch_model = scanner.model.model  # underlying torch.nn.Module\n",
    "    print(\"Underlying torch model type:\", type(torch_model))\n",
    "    # In mô tả ngắn và số lượng tham số\n",
    "    print(\"\\n--- Tóm tắt mô hình (repr) ---\")\n",
    "    print(torch_model)\n",
    "    try:\n",
    "        print(\"\\n--- Chi tiết kiến trúc từ torchinfo.summary ---\")\n",
    "        summary(torch_model, input_size=(1, 3, 640, 640))\n",
    "    except Exception as e:\n",
    "        print(\"Không thể chạy torchinfo.summary:\", e)\n",
    "    try:\n",
    "        total_params = sum(p.numel() for p in torch_model.parameters())\n",
    "        trainable = sum(p.numel() for p in torch_model.parameters() if p.requires_grad)\n",
    "        print(f\"\\nTổng tham số: {total_params:,}, Trainable: {trainable:,}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "except Exception as e:\n",
    "    print(\"Không thể truy cập scanner.model.model:\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
